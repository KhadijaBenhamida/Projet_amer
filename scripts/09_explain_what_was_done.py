"""
VERIFICATION CLASSIFICATION - QU'EST-CE QUI A ETE FAIT?
========================================================

Ce script explique et vÃ©rifie la classification crÃ©Ã©e.
"""

import pandas as pd
import json
from pathlib import Path

print("="*80)
print("VERIFICATION: QU'EST-CE QUI A ETE FAIT DANS LA CLASSIFICATION?")
print("="*80)

# 1. VÃ©rifier fichiers crÃ©Ã©s
print("\nðŸ“ FICHIERS CREES:")
files_to_check = [
    'data/processed/splits_classified/train_classified.parquet',
    'data/processed/splits_classified/val_classified.parquet',
    'data/processed/splits_classified/test_classified.parquet',
    'models/analysis/station_thresholds.json',
    'models/analysis/class_weights.json',
    'knowledge_base/climate_ontology.json'
]

for filepath in files_to_check:
    path = Path(filepath)
    if path.exists():
        size = path.stat().st_size / 1024 / 1024  # MB
        print(f"   âœ… {filepath} ({size:.2f} MB)")
    else:
        print(f"   âŒ {filepath} (MANQUANT)")

# 2. Charger et expliquer
print("\n" + "="*80)
print("EXPLICATION: NOUVELLE COLONNE 'extreme_event'")
print("="*80)

try:
    df = pd.read_parquet('data/processed/splits_classified/train_classified.parquet')
    
    print("\nðŸ“Š STRUCTURE DATASET:")
    print(f"   Lignes: {len(df):,}")
    print(f"   Colonnes: {len(df.columns)}")
    
    if 'extreme_event' in df.columns:
        print("\nâœ… COLONNE 'extreme_event' CREEE!")
        print("\n   Cette colonne contient la CLASSIFICATION des Ã©vÃ©nements:")
        
        event_labels = {
            0: 'Normal',
            1: 'Canicule_Extreme',
            2: 'Forte_Chaleur',
            3: 'Froid_Extreme',
            4: 'Froid_Prolonge'
        }
        
        print("\n   ðŸ“‹ DISTRIBUTION:")
        counts = df['extreme_event'].value_counts().sort_index()
        for cls, count in counts.items():
            pct = count / len(df) * 100
            label = event_labels.get(cls, f'Classe_{cls}')
            print(f"      {cls} ({label:17}): {count:8,} samples ({pct:5.2f}%)")
        
        # Exemples
        print("\n   ðŸ“ EXEMPLES (premiÃ¨res lignes):")
        cols_to_show = ['datetime', 'station_id', 'temperature', 'extreme_event']
        print(df[cols_to_show].head(10).to_string(index=False))
        
        # Exemples par classe
        print("\n   ðŸ” EXEMPLES PAR CLASSE:")
        for cls in sorted(df['extreme_event'].unique()):
            label = event_labels.get(cls, f'Classe_{cls}')
            sample = df[df['extreme_event'] == cls][['temperature', 'station_id']].iloc[0]
            print(f"      {cls} ({label:17}): T={sample['temperature']:6.2f}Â°C, Station={sample['station_id']}")
    
    else:
        print("\nâŒ COLONNE 'extreme_event' MANQUANTE!")
        print(f"   Colonnes prÃ©sentes: {list(df.columns)[:10]}...")

except Exception as e:
    print(f"\nâŒ ERREUR lecture dataset: {e}")

# 3. Expliquer seuils
print("\n" + "="*80)
print("EXPLICATION: SEUILS ADAPTATIFS PAR STATION")
print("="*80)

try:
    with open('models/analysis/station_thresholds.json') as f:
        thresholds = json.load(f)
    
    print("\nâœ… SEUILS CALCULES POUR CHAQUE STATION:")
    print("\n   Les seuils sont ADAPTATIFS (percentiles):")
    print("   - P99 (top 1%) = Canicule extrÃªme")
    print("   - P95 (top 5%) = Forte chaleur")
    print("   - P05 (bottom 5%) = Froid prolongÃ©")
    print("   - P01 (bottom 1%) = Froid extrÃªme")
    
    print("\n   ðŸ“Š SEUILS PAR STATION:")
    for station_id, thresh in thresholds.items():
        print(f"\n   Station {station_id}:")
        print(f"      Canicule extrÃªme: T > {thresh['temp_p99']:.1f}Â°C (P99)")
        print(f"      Forte chaleur:    {thresh['temp_p95']:.1f}Â°C < T â‰¤ {thresh['temp_p99']:.1f}Â°C")
        print(f"      Normal:           {thresh['temp_p05']:.1f}Â°C â‰¤ T â‰¤ {thresh['temp_p95']:.1f}Â°C")
        print(f"      Froid prolongÃ©:   {thresh['temp_p01']:.1f}Â°C â‰¤ T < {thresh['temp_p05']:.1f}Â°C")
        print(f"      Froid extrÃªme:    T < {thresh['temp_p01']:.1f}Â°C (P01)")

except Exception as e:
    print(f"\nâŒ ERREUR lecture seuils: {e}")

# 4. Class weights
print("\n" + "="*80)
print("EXPLICATION: CLASS WEIGHTS (pour entraÃ®nement)")
print("="*80)

try:
    with open('models/analysis/class_weights.json') as f:
        weights_info = json.load(f)
    
    print("\nâœ… CLASS WEIGHTS CALCULES:")
    print("   Ces poids compensent le dÃ©sÃ©quilibre des classes")
    print("   (Ã©vÃ©nements extrÃªmes rares vs normal frÃ©quent)")
    
    print("\n   âš–ï¸  POIDS PAR CLASSE:")
    for cls_str, weight in weights_info['class_weights'].items():
        label = weights_info['event_labels'].get(cls_str, f'Classe_{cls_str}')
        print(f"      {cls_str} ({label:17}): {weight:.4f}")
    
    print(f"\n   ðŸ“Š Ratio dÃ©sÃ©quilibre: {weights_info['imbalance_ratio']:.1f}:1")
    print(f"   ðŸŽ¯ Focal Loss utilisÃ©: {'OUI' if weights_info['use_focal_loss'] else 'NON'}")
    
    if weights_info['use_focal_loss']:
        print("\n   â„¹ï¸  Focal Loss (alpha=0.25, gamma=2.0) sera utilisÃ©")
        print("      car dÃ©sÃ©quilibre > 20:1")
        print("      â†’ Focus sur Ã©vÃ©nements rares difficiles Ã  prÃ©dire")

except Exception as e:
    print(f"\nâŒ ERREUR lecture weights: {e}")

# 5. Ontologie
print("\n" + "="*80)
print("EXPLICATION: ONTOLOGIE CLIMATIQUE")
print("="*80)

try:
    with open('knowledge_base/climate_ontology.json') as f:
        ontology = json.load(f)
    
    print("\nâœ… ONTOLOGIE CREEE:")
    print(f"   Concepts: {len(ontology['concepts'])}")
    print(f"   RÃ¨gles IF-THEN: {len(ontology['rules'])}")
    
    print("\n   ðŸ“‹ REGLES:")
    for rule in ontology['rules']:
        print(f"\n   {rule['id']}:")
        print(f"      Condition:  {rule['condition']}")
        print(f"      Conclusion: {rule['conclusion']}")
        print(f"      Alerte:     {rule['alert']}")

except Exception as e:
    print(f"\nâŒ ERREUR lecture ontologie: {e}")

# RESUME
print("\n" + "="*80)
print("RESUME: QU'EST-CE QUI A ETE FAIT?")
print("="*80)

print("""
âœ… ETAPE 1: CLASSIFICATION ADAPTATIVE

1. NOUVELLE COLONNE CREEE: 'extreme_event'
   - AjoutÃ©e aux datasets train/val/test
   - Valeurs: 0, 1, 2, 3, 4 (5 classes)
   - BasÃ©e sur TEMPERATURE et STATION

2. METHODE DE CLASSIFICATION:
   - Seuils ADAPTATIFS par station (percentiles)
   - Chaque station a SES PROPRES seuils P99, P95, P05, P01
   - Exemple:
     * Phoenix P99 = 45Â°C (Desert, trÃ¨s chaud)
     * Seattle P99 = 30Â°C (Oceanic, tempÃ©rÃ©)
   
3. CLASSES CREEES:
   0 = Normal           (85-90% donnÃ©es)
   1 = Canicule_Extreme (T > P99 station)
   2 = Forte_Chaleur    (P95 < T â‰¤ P99)
   3 = Froid_Extreme    (T < P01 station)
   4 = Froid_Prolonge   (P01 â‰¤ T < P05)

4. FICHIERS SUPPLEMENTAIRES:
   - station_thresholds.json: Seuils P99/P95/P05/P01 par station
   - class_weights.json: Poids pour compenser dÃ©sÃ©quilibre
   - climate_ontology.json: RÃ¨gles IF-THEN (conforme cahier)

5. POURQUOI ADAPTATIF?
   - 30Â°C Ã  Phoenix = Normal (frÃ©quent)
   - 30Â°C Ã  Seattle = Canicule (rare)
   â†’ Les percentiles dÃ©tectent ce qui est RARE LOCALEMENT
""")

print("\n" + "="*80)
print("ðŸš€ PROCHAINE ETAPE: ENTRAINEMENT LSTM")
print("="*80)
print("\nCommande: python scripts/07_train_lstm_FINAL.py")
print("DurÃ©e: 30-60 min")
print("Output: ModÃ¨le trained + mÃ©triques (F1, Recall, ROC-AUC)")
